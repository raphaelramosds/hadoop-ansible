- name: Laboratorio Hadoop
  hosts: all
  become: true
  vars:
    hosts_file: "hosts"
  tasks:
    - name: Atualizar repositorios
      apt:
        update_cache: yes
        state: latest

    - name: Instalar rsync
      apt:
        name: rsync
        state: present

    - name: Instalar todos os pacotes OpenJDK 11
      apt:
        name: "openjdk-11*"
        state: present
        update_cache: yes

    - name: Copiar hadoop
      synchronize:
        src: /root/hadoop-3.4.0
        dest: /root

    - name: Adicionar variáveis de ambiente do Hadoop ao .bashrc
      blockinfile:
        path: /root/.bashrc
        block: |
          # Hadoop environment variables
          export HADOOP_HOME="/root/hadoop-3.4.0"
          export HADOOP_COMMON_HOME="$HADOOP_HOME"
          export HADOOP_HDFS_HOME="$HADOOP_HOME"
          export HADOOP_MAPRED_HOME="$HADOOP_HOME"
          export HADOOP_YARN_HOME="$HADOOP_HOME"
          export HADOOP_CONF_DIR="$HADOOP_HOME/etc/hadoop"
          export HADOOP_COMMON_LIB_NATIVE_DIR="$HADOOP_HOME/lib/native"
          export HADOOP_OPTS="$HADOOP_OPTS -XX:-PrintWarnings -Djava.net.preferIPv4Stack=true -Djava.library.path=$HADOOP_COMMON_LIB_NATIVE_DIR"
          export LD_LIBRARY_PATH="$HADOOP_COMMON_LIB_NATIVE_DIR"
          export JAVA_HOME="/usr/lib/jvm/java-11-openjdk-amd64"
          export _JAVA_OPTIONS="-Xmx2048m"
          export PATH="$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$JAVA_HOME/bin"
          export HDFS_NAMENODE_USER="root"
          export HDFS_DATANODE_USER="$HDFS_NAMENODE_USER"
          export HDFS_SECONDARYNAMENODE_USER="$HDFS_NAMENODE_USER"
          export YARN_RESOURCEMANAGER_USER="$HDFS_NAMENODE_USER"
          export YARN_NODEMANAGER_USER="$HDFS_NAMENODE_USER"
        backup: yes

    - name: Copiar hosts
      synchronize:
        src: "{{ hosts_file }}"
        dest: /root        

    - name: Ler o arquivo hosts
      set_fact:
        hosts_content: "{{ lookup('file', 'hosts') }}"

    - name: Adicionar as entradas ao /etc/hosts
      lineinfile:
        path: /etc/hosts
        line: "{{ item }}"
        state: present
      with_items: "{{ hosts_content.splitlines() }}"

    - name: Remover diretorio data nos nodes
      file:
        path: /root/data
        state: absent

- name: Configuração do cluster   
  hosts: master
  become: true
  tasks:  
    - name: Parar maquinas do cluster
      command: stop-all.sh
      
    - name: Formatar HDFS
      command: hdfs namenode -format

    - name: Subir DFS
      command: start-dfs.sh

    - name: Subir yarn
      command: start-yarn.sh

    - name: Criar as pastas e copiar arquivos para o HDFS
      command: hdfs dfs -mkdir -p /user/root/input

    - name: Recuperar arquivos XML
      find:
        path: "{{ lookup('env', 'HADOOP_HOME') }}/etc/hadoop/"
        pattern: "*.xml"
      register: xml_files

    - name: Copiar arquivos para a pasta input
      command: hdfs dfs -put {{ item.path }} input
      with_items: "{{ xml_files.files }}"
